{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "## COVID_NER data review\n",
    "\n",
    "Testing files from ePMC team, reformatting to better suit use case of CeLLaTe model training\n",
    "Reasoning:\n",
    "    - Alot of the data available tends toward binning multiple entity types together\n",
    "    - Halted - on training with this model it showed a lot of data-leakage, with 208 sentences being identical matches in the train and test sets.\n",
    "    - Source data, COVID-NER, is worth keeping in mind for future given it is recorded at a document level. Also annotated for more entity types which may be of future interest.\n",
    "\n",
    "Sourced from https://github.com/tsantosh7/COVID-19-Named-Entity-Recognition/tree/master/Datasets/BIO/Anatomy_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/withers/GitProjects/OTAR3088/.venv/lib/python3.9/site-packages/urllib3/__init__.py:35: NotOpenSSLWarning: urllib3 v2 only supports OpenSSL 1.1.1+, currently the 'ssl' module is compiled with 'LibreSSL 2.8.3'. See: https://github.com/urllib3/urllib3/issues/3020\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "from typing import Dict, List, Optional\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>token</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>RNA</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>transcripts</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>were</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>packaged</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>into</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>both</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>BCV</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>and</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>MHV</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>virions</td>\n",
       "      <td>B-ANAT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>when</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>the</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>cloned</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>region</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>was</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>appended</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>to</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>a</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>noncoronavirus</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>RNA</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             token   label\n",
       "0              RNA       O\n",
       "1      transcripts       O\n",
       "2             were       O\n",
       "3         packaged       O\n",
       "4             into       O\n",
       "5             both       O\n",
       "6              BCV       O\n",
       "7              and       O\n",
       "8              MHV       O\n",
       "9          virions  B-ANAT\n",
       "10            when       O\n",
       "11             the       O\n",
       "12          cloned       O\n",
       "13          region       O\n",
       "14             was       O\n",
       "15        appended       O\n",
       "16              to       O\n",
       "17               a       O\n",
       "18  noncoronavirus       O\n",
       "19             RNA       O"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "source_path = \"/Users/withers/GitProjects/COVID-19-Named-Entity-Recognition/Datasets/BIO/Anatomy_dataset/train.csv\"\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "def read_bio_file(filepath: str) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Read-in BIO file, parsing to assign token / labels to columns\n",
    "    Returns pd.DataFrame\n",
    "    \"\"\"\n",
    "    sentences = []\n",
    "    sentence = []\n",
    "\n",
    "    with open(filepath, 'r') as file:\n",
    "        for line in file:\n",
    "            line = line.strip()\n",
    "            if line == \"\":\n",
    "                if sentence:\n",
    "                    sentences.append(sentence)\n",
    "                    sentence = []\n",
    "            else:\n",
    "                parts = line.split()\n",
    "                if len(parts) == 2:\n",
    "                    token, label = parts\n",
    "                    sentence.append((token, label))\n",
    "                else:\n",
    "                    print(f\"Issue with line: {line}\")\n",
    "\n",
    "        # Catch last sentence\n",
    "        if sentence:\n",
    "            sentences.append(sentence)\n",
    "\n",
    "    # Parse into DataFrame\n",
    "    tokens = []\n",
    "    labels = []\n",
    "\n",
    "    for sent in sentences:\n",
    "        for token, label in sent:\n",
    "            tokens.append(token)\n",
    "            labels.append(label)\n",
    "\n",
    "    df = pd.DataFrame({\n",
    "        'token': tokens,\n",
    "        'label': labels\n",
    "    })\n",
    "\n",
    "    return df\n",
    "\n",
    "input_df = read_bio_file(source_path)\n",
    "input_df.head(n=20)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Read-in dictionaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>term</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>P3HR-1</td>\n",
       "      <td>Cell</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>UCLA P-3</td>\n",
       "      <td>Cell</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>UMSCC22B</td>\n",
       "      <td>Cell</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>UMUC3</td>\n",
       "      <td>Cell</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>V79-4</td>\n",
       "      <td>Cell</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3824</th>\n",
       "      <td>vulva</td>\n",
       "      <td>Tissue</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3825</th>\n",
       "      <td>white adipose tissue</td>\n",
       "      <td>Tissue</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3826</th>\n",
       "      <td>white muscle</td>\n",
       "      <td>Tissue</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3827</th>\n",
       "      <td>whole body</td>\n",
       "      <td>Tissue</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3828</th>\n",
       "      <td>xylem</td>\n",
       "      <td>Tissue</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3829 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                      term   label\n",
       "0                   P3HR-1    Cell\n",
       "1                 UCLA P-3    Cell\n",
       "2                 UMSCC22B    Cell\n",
       "3                    UMUC3    Cell\n",
       "4                    V79-4    Cell\n",
       "...                    ...     ...\n",
       "3824                 vulva  Tissue\n",
       "3825  white adipose tissue  Tissue\n",
       "3826          white muscle  Tissue\n",
       "3827            whole body  Tissue\n",
       "3828                 xylem  Tissue\n",
       "\n",
       "[3829 rows x 2 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dict_file = \"/Users/withers/GitProjects/OTAR3088/Data_mining/labelstudio_e2e/output/labelstudio/master_dictionary.tsv\"\n",
    "dictionary = pd.read_csv(dict_file, sep=\"\\t\")\n",
    "map = {\"CELL\": \"Cell\", \"TISSUE\": \"Tissue\"}\n",
    "dictionary[\"label\"] = dictionary[\"label\"].map(map)\n",
    "dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_df[\"token_lower\"] = input_df[\"token\"].str.lower()\n",
    "dictionary[\"term_lower\"] = dictionary[\"term\"].str.lower()\n",
    "\n",
    "def dictionary_tagging(token):\n",
    "    if token in dictionary[\"term_lower\"]:\n",
    "        print(token)\n",
    "        matched = dictionary[dictionary[\"term_lower\"] == token]\n",
    "        return matched[\"label\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "49383\n"
     ]
    }
   ],
   "source": [
    "# Grab text from df, split into sentences\n",
    "all_text = \" \".join(input_df[\"token\"].to_list())\n",
    "all_sent = all_text.split(sep=\" . \")\n",
    "print(len(all_sent))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Count of entities tagged by dictionaries: 38741\n"
     ]
    }
   ],
   "source": [
    "import spacy\n",
    "import pandas as pd\n",
    "from spacy.matcher import PhraseMatcher\n",
    "\n",
    "# Load SpaCy model\n",
    "nlp = spacy.load(\"en_core_web_sm\", disable=[\"parser\", \"ner\", \"tagger\", \"lemmatizer\"])\n",
    "\n",
    "def tag_sentences_with_dictionary(dict_df: Dict, sentences: List, term_column: str, tag_column: str) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    dict_df: DataFrame with term & label columns, specified in term_column & tag_column declarations\n",
    "    sentences: list of sentences to tag\n",
    "    Returns: pd.DataFrame\n",
    "    \"\"\"\n",
    "    # Dictionary matching obj\n",
    "    matcher = PhraseMatcher(nlp.vocab, attr=\"LOWER\")\n",
    "\n",
    "    # Add patterns to matcher\n",
    "    for _, row in dict_df.iterrows():\n",
    "        term = row[term_column]\n",
    "        tag = row[tag_column]\n",
    "        # Tokenize and make named entities of terms\n",
    "        # Formalizing dictionary for matching quickly\n",
    "        pattern = nlp.make_doc(term)\n",
    "        matcher.add(tag, [pattern])\n",
    "\n",
    "    all_tokens = []\n",
    "    all_labels = []\n",
    "\n",
    "    for doc in nlp.pipe(sentences, batch_size=64):\n",
    "        # Prep sentence - tokenize, etc\n",
    "        tags = [\"O\"] * len(doc)\n",
    "\n",
    "        matches = matcher(doc)\n",
    "\n",
    "        # Map match id to tag (ID -> String)\n",
    "        for match_id, start, end in matches:\n",
    "            tag = nlp.vocab.strings[match_id]\n",
    "            for i in range(start, end):\n",
    "                tags[i] = tag\n",
    "\n",
    "        all_tokens.extend([token.text for token in doc])\n",
    "        all_labels.extend(tags)\n",
    "\n",
    "    result_df = pd.DataFrame({\n",
    "        \"token\": all_tokens,\n",
    "        \"dict_label\": all_labels\n",
    "    })\n",
    "\n",
    "    return result_df\n",
    "\n",
    "res_df = tag_sentences_with_dictionary(dict_df=dictionary, sentences=all_sent, term_column=\"term\", tag_column=\"label\")\n",
    "print(f\"Count of entities tagged by dictionaries: {len(res_df[res_df['dict_label'] != 'O'])}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>token</th>\n",
       "      <th>dict_label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>RNA</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>transcripts</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>were</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>packaged</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>into</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1291029</th>\n",
       "      <td>and</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1291030</th>\n",
       "      <td>connective</td>\n",
       "      <td>Tissue</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1291031</th>\n",
       "      <td>tissue</td>\n",
       "      <td>Tissue</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1291032</th>\n",
       "      <td>diseases</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1291033</th>\n",
       "      <td>.</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1291034 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               token dict_label\n",
       "0                RNA          O\n",
       "1        transcripts          O\n",
       "2               were          O\n",
       "3           packaged          O\n",
       "4               into          O\n",
       "...              ...        ...\n",
       "1291029          and          O\n",
       "1291030   connective     Tissue\n",
       "1291031       tissue     Tissue\n",
       "1291032     diseases          O\n",
       "1291033            .          O\n",
       "\n",
       "[1291034 rows x 2 columns]"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "isnull_df = res_df[res_df[\"dict_label\"].isna()]\n",
    "len(isnull_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Count of entities tagged by manual curation: 86467\n"
     ]
    }
   ],
   "source": [
    "print(f\"Count of entities tagged by manual curation: {len(input_df[input_df['label'] != 'O'])}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>token</th>\n",
       "      <th>label</th>\n",
       "      <th>token_lower</th>\n",
       "      <th>dict_label</th>\n",
       "      <th>dict_label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>RNA</td>\n",
       "      <td>O</td>\n",
       "      <td>rna</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>transcripts</td>\n",
       "      <td>O</td>\n",
       "      <td>transcripts</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>were</td>\n",
       "      <td>O</td>\n",
       "      <td>were</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>packaged</td>\n",
       "      <td>O</td>\n",
       "      <td>packaged</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>into</td>\n",
       "      <td>O</td>\n",
       "      <td>into</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         token label  token_lower dict_label dict_label\n",
       "0          RNA     O          rna          O          O\n",
       "1  transcripts     O  transcripts          O          O\n",
       "2         were     O         were          O          O\n",
       "3     packaged     O     packaged          O          O\n",
       "4         into     O         into          O          O"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merged_df = pd.concat([input_df, res_df[\"dict_label\"]], axis=1)\n",
    "merged_df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4235"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "overlap_count = comparison_df[(comparison_df[\"label\"] != \"O\") & (comparison_df[\"dict_label\"] != \"O\")]\n",
    "len(overlap_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>token</th>\n",
       "      <th>label</th>\n",
       "      <th>token_lower</th>\n",
       "      <th>dict_label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>79</th>\n",
       "      <td>lower</td>\n",
       "      <td>B-ANAT</td>\n",
       "      <td>lower</td>\n",
       "      <td>Tissue</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80</th>\n",
       "      <td>respiratory</td>\n",
       "      <td>I-ANAT</td>\n",
       "      <td>respiratory</td>\n",
       "      <td>Tissue</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>81</th>\n",
       "      <td>tract</td>\n",
       "      <td>I-ANAT</td>\n",
       "      <td>tract</td>\n",
       "      <td>Tissue</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>112</th>\n",
       "      <td>lung</td>\n",
       "      <td>B-ANAT</td>\n",
       "      <td>lung</td>\n",
       "      <td>Tissue</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>735</th>\n",
       "      <td>calf</td>\n",
       "      <td>B-ANAT</td>\n",
       "      <td>calf</td>\n",
       "      <td>Tissue</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1321220</th>\n",
       "      <td>tract</td>\n",
       "      <td>I-ANAT</td>\n",
       "      <td>tract</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1321239</th>\n",
       "      <td>immune</td>\n",
       "      <td>B-ANAT</td>\n",
       "      <td>immune</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1321240</th>\n",
       "      <td>system</td>\n",
       "      <td>I-ANAT</td>\n",
       "      <td>system</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1321282</th>\n",
       "      <td>connective</td>\n",
       "      <td>B-ANAT</td>\n",
       "      <td>connective</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1321283</th>\n",
       "      <td>tissue</td>\n",
       "      <td>I-ANAT</td>\n",
       "      <td>tissue</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4235 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               token   label  token_lower dict_label\n",
       "79             lower  B-ANAT        lower     Tissue\n",
       "80       respiratory  I-ANAT  respiratory     Tissue\n",
       "81             tract  I-ANAT        tract     Tissue\n",
       "112             lung  B-ANAT         lung     Tissue\n",
       "735             calf  B-ANAT         calf     Tissue\n",
       "...              ...     ...          ...        ...\n",
       "1321220        tract  I-ANAT        tract        NaN\n",
       "1321239       immune  B-ANAT       immune        NaN\n",
       "1321240       system  I-ANAT       system        NaN\n",
       "1321282   connective  B-ANAT   connective        NaN\n",
       "1321283       tissue  I-ANAT       tissue        NaN\n",
       "\n",
       "[4235 rows x 4 columns]"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "overlap_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>token</th>\n",
       "      <th>label</th>\n",
       "      <th>token_lower</th>\n",
       "      <th>dict_tag</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [token, label, token_lower, dict_tag]\n",
       "Index: []"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "show = input_df[input_df[\"dict_tag\"].notnull()]\n",
    "show"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "\n",
    "def sent_from_df_col(column: pd.Series) -> List:\n",
    "    return \" \".join(column.to_list())\n",
    "\n",
    "def lemmatize_term(term: str) -> str:\n",
    "    \"\"\"\n",
    "    Return lemmatized form of term\n",
    "    \"\"\"\n",
    "    lower = nlp(term.lower())\n",
    "    lemmat = ' '.join([token.lemma_ for token in lower])\n",
    "    return lemmat\n",
    "\n",
    "def dictionary_tagging(dict_file: pd.DataFrame, texts: pd.DataFrame, token_col: Optional[str] = \"token\") -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Tag terms in strings representing column of BIO file containing tokens\n",
    "    Return dictioanry labels as new column within texts DataFrame\n",
    "    \"\"\"\n",
    "    # Map lemmatized terms to input dictionary terms\n",
    "    term_lemma_map = {}\n",
    "    for row in dict_file:\n",
    "        term = row['term'].lower()\n",
    "        label = row['label']\n",
    "        lemma = lemmatize_term(term)\n",
    "        term_lemma_map[lemma] = (term, label)\n",
    "\n",
    "    # Read and process input texts\n",
    "    texts = [token.strip() for token in texts[\"token\"]]\n",
    "\n",
    "    annotations = []\n",
    "\n",
    "    for text in texts:\n",
    "        doc = nlp(text)\n",
    "        tokens = [token for token in doc]\n",
    "        ## Print next line to display lemmatizations\n",
    "        # lemmatized_text = ' '.join([token.lemma_.lower() for token in tokens])\n",
    "        results = []\n",
    "\n",
    "        # Try to match given term's lemma in lemmatized version of the text\n",
    "        for lemma, (orig_term, label) in term_lemma_map.items():\n",
    "            lemma_tokens = lemma.split()\n",
    "            n = len(lemma_tokens)\n",
    "            for i in range(len(tokens) - n + 1):\n",
    "                window = tokens[i:i + n]\n",
    "                window_lemmas = [t.lemma_.lower() for t in window]\n",
    "\n",
    "                if window_lemmas == lemma_tokens and window:\n",
    "                    start_char = window[0].idx\n",
    "                    end_char = window[-1].idx + len(window[-1])\n",
    "                    results.append({\n",
    "                        \"from_name\": \"label\",\n",
    "                        \"to_name\": \"text\",\n",
    "                        \"type\": \"labels\",\n",
    "                        \"value\": {\n",
    "                            \"start\": start_char,\n",
    "                            \"end\": end_char,\n",
    "                            \"text\": text[start_char:end_char],\n",
    "                            \"labels\": [label]\n",
    "                        }\n",
    "                    })\n",
    "        if pmcid:\n",
    "            text = text + '\\n' + f'Source paper: {pmcid}'\n",
    "        res = {\n",
    "            \"data\": {\"text\": text},\n",
    "            \"annotations\": [{\"result\": results}] if results else []\n",
    "        }\n",
    "        annotations.append(res)\n",
    "\n",
    "    # Save annotations output\n",
    "    with open(output_json, 'w', encoding='utf-8') as f:\n",
    "        json.dump(annotations, f, indent=2, ensure_ascii=False)\n",
    "    # hits = len(annotations[0]['annotations'][0]['result'])\n",
    "    # print(f\"Saved {hits} dictionary annotation(s) to {output_json}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
